{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74b46b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lancedb/__init__.py:220: UserWarning: lance is not fork-safe. If you are using multiprocessing, use spawn instead.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygithub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: lancedb in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.22.0)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pygithub) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pygithub) (2.32.3)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyjwt[crypto]>=2.4.0->pygithub) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pygithub) (4.13.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pygithub) (2.2.3)\n",
      "Requirement already satisfied: Deprecated in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pygithub) (1.2.18)\n",
      "Requirement already satisfied: deprecation in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (2.1.0)\n",
      "Requirement already satisfied: overrides>=0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (7.7.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (24.1)\n",
      "Requirement already satisfied: pyarrow>=14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (20.0.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (2.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lancedb) (4.67.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (0.4.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyjwt[crypto]>=2.4.0->pygithub) (44.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->pygithub) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->pygithub) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.14.0->pygithub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.14.0->pygithub) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.14.0->pygithub) (2024.8.30)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Deprecated->pygithub) (1.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pygithub lancedb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83ac81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "from itertools import islice    #con of popular repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2965876",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=Github(\"your_github_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad5b5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = g.get_repo(\"NVIDIA/physicsnemo\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56ddead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_issues = [\n",
    "    {\n",
    "        \"number\": issue.number,\n",
    "        \"title\": issue.title,\n",
    "        \"body\": issue.body or \"\",\n",
    "        \"url\": issue.html_url\n",
    "    }\n",
    "    for issue in islice(repo.get_issues(state=\"all\"), 20)\n",
    "    if issue.pull_request is None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e684e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67945aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = [f\"{issue['title']} {issue['body']}\" for issue in raw_issues]\n",
    "embeddings = model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "808b2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lancedb baby\n",
    "import lancedb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to float32 for proper vector storage\n",
    "embeddings = np.array(embeddings, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b609fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=lancedb.connect(\"github-issues\")\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"text\": texts[i],\n",
    "        \"embedding\": embeddings[i].tolist(),  # Ensure it's a list of floats (vector)\n",
    "        \"url\": raw_issues[i][\"url\"],\n",
    "        \"number\": raw_issues[i][\"number\"]\n",
    "    }\n",
    "    for i in range(len(texts))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e843fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = db.create_table(\"issues\", data=df, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fbbc90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for similarity search we are using faiss,cause there were issue with vector search with lancedb\n",
    "import faiss\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance metric\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1b5e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"🐛[BUG]: TypeError: RegressionLoss.__call__() got an unexpected keyword argument 'use_patch_grad_acc'\", 'Question : CorrDiff Loss Function (SSE or MSE)', '🐛[BUG]: @StaticCaptureEvaluateNoGrad decorator can cause NaN values to show up during inference', '📚[DOC]: CorrDiff Validation and Early Stopping', '🚀[FEA]: Shall I use HRRR datasets in natural/hybrid model levels when training the StormCast model?']\n"
     ]
    }
   ],
   "source": [
    "#query\n",
    "query = \"authentication error\"\n",
    "query_embedding = model.encode([query])[0].astype(np.float32)\n",
    "k = 5\n",
    "D, I = index.search(np.array([query_embedding]), k)\n",
    "results = [raw_issues[i][\"title\"] for i in I[0]]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8349bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([f\"Issue {i+1}:\\n{body}\" for i, body in enumerate(results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90004946",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a helpful assistant. Here are some GitHub issues:\n",
    "\n",
    "{context}\n",
    "Summarize the common problems or patterns described in these issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ee9643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini  \n",
    "from agno.tools.reasoning import ReasoningTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65832275",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=Gemini(id=\"models/gemini-2.0-flash-lite\"),\n",
    "    tools=[ReasoningTools(add_instructions=True)],\n",
    "    instructions=[\"Identify important themes, group similar issues, and highlight core problems in one line\"],\n",
    "    markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b33a49c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gemini Summary ===\n",
      "\n",
      "RunResponse(content=\"Okay, I've reviewed the issues. Here's a breakdown of the common problems and patterns:\\n\\n*   **Bug Reports:** Issues 1 and 3 are clearly bug reports. Issue 1 describes a `TypeError` related to an unexpected keyword argument, while Issue 3 mentions `NaN` values appearing during inference due to a decorator. These are specific technical issues within the code.\\n*   **Loss Function and Training:** Issues 2 and 4 relate to the loss function and the training process. Issue 2 asks a question about the loss function, specifically whether to use SSE or MSE, and Issue 4 discusses validation and early stopping related to the CorrDiff loss function.\\n*   **Feature Request:** Issue 5 is a feature request concerning the use of HRRR datasets within a model during training.\\n\\nBased on this, the core problems or patterns seem to be:\\n\\n1.  **Software Bugs:** Specific errors and unexpected behavior within the code (Issues 1 and 3).\\n2.  **Model Training/Optimization:** Questions and considerations around loss functions, validation, and early stopping (Issues 2 and 4).\\n3.  **Feature Implementation:** Requests for new features or data integration (Issue 5).\\n\", content_type='str', thinking=None, reasoning_content=\"## Summarize GitHub Issues\\nThe user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\\nAction: Read and analyze each issue.\\n\\n\", event='RunResponse', messages=[Message(role='system', content='<instructions>\\nIdentify important themes, group similar issues, and highlight core problems in on line\\n</instructions>\\n\\n<additional_information>\\n- Use markdown to format your answers.\\n</additional_information>\\n\\n<reasoning_instructions>\\nYou have access to the `think` and `analyze` tools to work through problems step-by-step and structure your thought process. You must ALWAYS `think` before making tool calls or generating a response.\\n\\n1. **Think** (scratchpad):\\n    - Purpose: Use the `think` tool as a scratchpad to break down complex problems, outline steps, and decide on immediate actions within your reasoning flow. Use this to structure your internal monologue.\\n    - Usage: Call `think` before making tool calls or generating a response. Explain your reasoning and specify the intended action (e.g., \"make a tool call\", \"perform calculation\", \"ask clarifying question\").\\n\\n2. **Analyze** (evaluation):\\n    - Purpose: Evaluate the result of a think step or a set of tool calls. Assess if the result is expected, sufficient, or requires further investigation.\\n    - Usage: Call `analyze` after a set of tool calls. Determine the `next_action` based on your analysis: `continue` (more reasoning needed), `validate` (seek external confirmation/validation if possible), or `final_answer` (ready to conclude).\\n    - Explain your reasoning highlighting whether the result is correct/sufficient.\\n\\n## IMPORTANT GUIDELINES\\n- **Always Think First:** You MUST use the `think` tool before making tool calls or generating a response.\\n- **Iterate to Solve:** Use the `think` and `analyze` tools iteratively to build a clear reasoning path. The typical flow is `Think` -> [`Tool Calls` if needed] -> [`Analyze` if needed] -> ... -> `final_answer`. Repeat this cycle until you reach a satisfactory conclusion.\\n- **Make multiple tool calls in parallel:** After a `think` step, you can make multiple tool calls in parallel.\\n- **Keep Thoughts Internal:** The reasoning steps (thoughts and analyses) are for your internal process only. Do not share them directly with the user.\\n- **Conclude Clearly:** When your analysis determines the `next_action` is `final_answer`, provide a concise and accurate final answer to the user.\\n</reasoning_instructions>', name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, thinking=None, redacted_thinking=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=MessageMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=None, time_to_first_token=None, timer=None), references=None, created_at=1746546556), Message(role='user', content=\"\\nYou are a helpful assistant. Here are some GitHub issues:\\n\\nIssue 1:\\n🐛[BUG]: TypeError: RegressionLoss.__call__() got an unexpected keyword argument 'use_patch_grad_acc'\\n\\nIssue 2:\\nQuestion : CorrDiff Loss Function (SSE or MSE)\\n\\nIssue 3:\\n🐛[BUG]: @StaticCaptureEvaluateNoGrad decorator can cause NaN values to show up during inference\\n\\nIssue 4:\\n📚[DOC]: CorrDiff Validation and Early Stopping\\n\\nIssue 5:\\n🚀[FEA]: Shall I use HRRR datasets in natural/hybrid model levels when training the StormCast model?\\nSummarize the common problems or patterns described in these issues.\\n\", name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, thinking=None, redacted_thinking=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=MessageMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=None, time_to_first_token=None, timer=None), references=None, created_at=1746546556), Message(role='assistant', content=None, name=None, tool_call_id=None, tool_calls=[{'id': '7f819b30-1682-4fe6-ab2e-077cbc55ba8b', 'type': 'function', 'function': {'name': 'think', 'arguments': '{\"title\": \"Summarize GitHub Issues\", \"action\": \"Read and analyze each issue.\", \"thought\": \"The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I\\'ll group similar issues and highlight the core problems.\"}'}}], audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, thinking=None, redacted_thinking=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=MessageMetrics(input_tokens=871, output_tokens=53, total_tokens=924, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=1.1827761250024196, time_to_first_token=None, timer=<agno.utils.timer.Timer object at 0x1783348c0>), references=None, created_at=1746546556), Message(role='tool', content=[\"Step 1:\\nTitle: Summarize GitHub Issues\\nReasoning: The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\\nAction: Read and analyze each issue.\\nConfidence: 0.8\"], name=None, tool_call_id=None, tool_calls=[{'tool_name': 'think', 'content': \"Step 1:\\nTitle: Summarize GitHub Issues\\nReasoning: The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\\nAction: Read and analyze each issue.\\nConfidence: 0.8\"}], audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, thinking=None, redacted_thinking=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=MessageMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=0.000795749991084449, time_to_first_token=None, timer=None), references=None, created_at=1746546557), Message(role='assistant', content=\"Okay, I've reviewed the issues. Here's a breakdown of the common problems and patterns:\\n\\n*   **Bug Reports:** Issues 1 and 3 are clearly bug reports. Issue 1 describes a `TypeError` related to an unexpected keyword argument, while Issue 3 mentions `NaN` values appearing during inference due to a decorator. These are specific technical issues within the code.\\n*   **Loss Function and Training:** Issues 2 and 4 relate to the loss function and the training process. Issue 2 asks a question about the loss function, specifically whether to use SSE or MSE, and Issue 4 discusses validation and early stopping related to the CorrDiff loss function.\\n*   **Feature Request:** Issue 5 is a feature request concerning the use of HRRR datasets within a model during training.\\n\\nBased on this, the core problems or patterns seem to be:\\n\\n1.  **Software Bugs:** Specific errors and unexpected behavior within the code (Issues 1 and 3).\\n2.  **Model Training/Optimization:** Questions and considerations around loss functions, validation, and early stopping (Issues 2 and 4).\\n3.  **Feature Implementation:** Requests for new features or data integration (Issue 5).\\n\", name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, thinking=None, redacted_thinking=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=MessageMetrics(input_tokens=995, output_tokens=257, total_tokens=1252, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=2.4788393749913666, time_to_first_token=None, timer=<agno.utils.timer.Timer object at 0x178337da0>), references=None, created_at=1746546557)], metrics={'input_tokens': [871, 995], 'output_tokens': [53, 257], 'total_tokens': [924, 1252], 'audio_tokens': [0, 0], 'input_audio_tokens': [0, 0], 'output_audio_tokens': [0, 0], 'cached_tokens': [0, 0], 'reasoning_tokens': [0, 0], 'prompt_tokens': [0, 0], 'completion_tokens': [0, 0], 'time': [1.1827761250024196, 2.4788393749913666]}, model='models/gemini-2.0-flash-lite', run_id='2b689fb0-f8e6-42c0-8a11-637766df0721', agent_id='4df4b3f1-b178-4635-ad33-c1bea3a2aa9a', session_id='88c01872-2fc1-4a43-8c52-0128dbf44da2', workflow_id=None, tools=[{'content': \"Step 1:\\nTitle: Summarize GitHub Issues\\nReasoning: The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\\nAction: Read and analyze each issue.\\nConfidence: 0.8\", 'tool_call_id': '7f819b30-1682-4fe6-ab2e-077cbc55ba8b', 'tool_name': 'think', 'tool_args': {'title': 'Summarize GitHub Issues', 'action': 'Read and analyze each issue.', 'thought': \"The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\"}, 'tool_call_error': False, 'metrics': MessageMetrics(input_tokens=0, output_tokens=0, total_tokens=0, audio_tokens=0, input_audio_tokens=0, output_audio_tokens=0, cached_tokens=0, reasoning_tokens=0, prompt_tokens=0, completion_tokens=0, prompt_tokens_details=None, completion_tokens_details=None, additional_metrics=None, time=0.000795749991084449, time_to_first_token=None, timer=None), 'created_at': 1746546557}], formatted_tool_calls=[\"think(title=Summarize GitHub Issues, action=Read and analyze each issue., thought=The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.)\"], images=None, videos=None, audio=None, response_audio=None, citations=None, extra_data=RunResponseExtraData(references=None, add_messages=None, reasoning_steps=[ReasoningStep(title='Summarize GitHub Issues', action='Read and analyze each issue.', result=None, reasoning=\"The user wants me to summarize common problems or patterns in the GitHub issues. I should read each issue and identify key themes. Then, I'll group similar issues and highlight the core problems.\", next_action=<NextAction.CONTINUE: 'continue'>, confidence=None)], reasoning_messages=None), created_at=1746545853)\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(prompt)\n",
    "print(\"\\n=== Gemini Summary ===\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1ff02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
